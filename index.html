<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>3D GAN Inversion with Pose Optimization</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">3D GAN Inversion with Pose Optimization</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">Jaehoon Ko</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=ToQ-jEIAAAAJ&hl=en&oi=ao">Kyusun Cho</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://github.com/ChoiDae1">Daewon Choi</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://cvlab.korea.ac.kr/members">Kwangrok Ryoo</a><sup>1,2</sup>,
            </span>
            <span class="author-block">
              <a href="https://cvlab.korea.ac.kr/members">Seungryong Kim</a><sup>1</sup>,
            </span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Korea University,</span>
            <span class="author-block"><sup>2</sup>LG AI Research</span>
          </div>
          <h1 style="font-size:24px;font-weight:bold">WACV 2023</h1>
          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href="#"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2210.07301"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link.
              <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="subtitle has-text-centered">
        Code and additional results will be available soon. Stay tuned!
      </h2>
      <video id="teaser" autoplay muted loop playsinline height="100%" style="border:1px solid black;">
        <source src="static/images/tim_cook.mp4"
                type="video/mp4">
      </video>
      <video id="teaser" autoplay muted loop playsinline height="100%" style="border:1px solid black;">
        <source src="static/images/jaeyonglee.mp4"
                type="video/mp4">
      </video>
    </div>
  </div>
</section>

<!-- 
<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            With the recent advances in NeRF-based 3D aware GANs quality,
            projecting an image into the latent space of these 3D-aware GANs has a natural advantage over
            2D GAN inversion: not only does it allow multi-view consistent editing of the projected image, 
            but it also enables 3D reconstruction and novel view synthesis when given only a single image.
            However, the explicit viewpoint control acts as a main hindrance in the 3D GAN inversion process,
            as both camera pose and latent code have to be optimized simultaneously to reconstruct the given image.
            Most works that explore the latent space of the 3D-aware GANs rely on ground-truth camera viewpoint or deformable 3D model,
            thus limiting their applicability.
            In this work, we introduce a generalizable 3D GAN inversion method that infers camera viewpoint and latent code simultaneously
            to enable multi-view consistent semantic image editing.
            The key to our approach is to leverage pre-trained estimators for better initialization and utilize the pixel-wise depth calculated from NeRF parameters 
            to better reconstruct the given image.
            We conduct extensive experiments on image reconstruction and editing both quantitatively and qualitatively,
            and further compare our results with 2D GAN-based editing to demonstrate the advantages of utilizing the latent space of 3D GANs.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video.
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->
  </div> 
</section>


<section class="section">
  <div class="container">
    <div align="center" style="margin-top:20px;" style="margin-bottom:120px;">
      <h2 class="title is-3">Our Optimization Scheme</h2>
      <img style='height: auto; width: 45%; object-fit: contain' src="static/images/main_image.png" alt="overview_image">
    </div> 
  </div>
    <p></p>
    <br>
    <p></p>
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <!-- Visual Effects. -->
      <div class="column">
        <div class="content">
          <h4 style="font-size:22px", class="title is-3">Pre-trained Networks for Initialization</h4>
          <p>
            We pre-train a camera pose estiamtor and latent code encoder for better initialization of the optimization process, 
            by training the respective newtorks on a generated pseudo pair dataset. 
          </p>
          <!-- <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/dollyzoom-stacked.mp4"
                    type="video/mp4">
          </video> -->
        </div>
      </div>
      <!--/ Visual Effects. -->
      <div class="column">
        <div class="content">
          <h4 style="font-size:22px", class="title is-3">Optimization using Depth-based Warping</h4>
          <p>
            We use the depth map calculated from NeRF parameters and compare the estimated depth from the obtained camrea pose and projected depth from a canoncial viewpoint 
            which allows us to optimize the latent code and camera pose simultaneously.
          </p>
          <!-- <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/dollyzoom-stacked.mp4"
                    type="video/mp4">
          </video> -->
        </div>
      </div>
      <!-- Matting. -->
      <div class="column">
        <h4 style="font-size:22px", class="title is-3">Generater Tuning with Depth Regularization</h4>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              We fine tune the generator for a more accurate reconstruction of the given image by adding a depth regularization term to the loss function.
            </p>
            <!-- <video id="matting-video" controls playsinline height="100%">
              <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/matting.mp4"
                      type="video/mp4">
            </video> -->
          </div>

        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container">
    <div align="center" style="margin-top:20px;" style="margin-bottom:120px;">
      <h2 class="title is-3">Reconstruction Results</h2>
      <img style='height: auto; width: 75%; object-fit: contain' src="static/images/results1.png" alt="overview_image">
    </div> 
  </div>
</section>





<section class="section">
  <div class="container is-max-desktop">
    <!-- Concurrent Work. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          <p>
            Our method was implemented on <a href="https://nvlabs.github.io/eg3d/">EG3D</a>, the state-of-the-art nerf-based 3D-aware GAN model. 
          </p>
          <p>
            Our method was built upon <a href="https://arxiv.org/abs/2106.05744">Pivotal Tuning</a>, a popular and simple method for 2D GAN inversion.
          </p>
          <p>
            Our depth-based optimization scheme was inspired by <a href="https://openaccess.thecvf.com/content_cvpr_2017/papers/Zhou_Unsupervised_Learning_of_CVPR_2017_paper.pdf">monocular depth estimation</a> literature.
          </p>
          <p>
            We borrowed the idea of using a depth smoothness regularization during the generator tuning step from <a href="https://m-niemeyer.github.io/regnerf/">RegNeRF</a>.
          </p>
          <p>
            There's a lot of excellent work that was introduced around the same time as ours, but most of them requires <a href="https://arxiv.org/abs/2112.09061">ground-truth camera pose</a> or <a href="https://www.computationalimaging.org/publications/3dganinversion/">3D morphable models</a>.
          </p>
        </div>
      </div>
    </div>
    <!--/ Concurrent Work. -->

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{ko20233d,
  author    = {Ko, Jaehoon and Cho, Kyusun and Choi, Daewon and Ryoo, Kwangrok and Kim, Seungryong},
  title     = {3D GAN Inversion with Pose Optimization},
  journal   = {WACV},
  year      = {2023},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="#">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <h2 class="subtitle has-text-centered">
        <div class="content">
            This website is borrowed from <a href="https://github.com/nerfies/nerfies.github.io">nerfies</a>.
            We thank the authors for open-sourcing the source code. 
        </div>
      </h2>
    </div>
  </div>
</footer>

</body>
</html>
